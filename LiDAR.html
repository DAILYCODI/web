<!-- Dazarus Chapman -->
<!DOCTYPE html>
<html>
    <!-- Head section containing metadata and external resources -->
    <html lang="en">
        <head>
           <!-- Character set and viewport settings -->
          <meta charset="UTF-8">
          <meta name="viewport" content="width=device-width, initial-scale=1.0">

          <!-- Link to external CSS file -->
          <link rel="stylesheet" href="sty.css">

          <!-- External script for jQuery library -->
          <script src="https://code.jquery.com/jquery-3.6.4.min.js"></script>

          <!-- Asynchronous script inclusion for better page loading performance -->
          <script defer src="script.js"></script>

          <!-- Title of the webpage -->
          <title>Functional Navigation</title>
        </head>
        <!-- Body of the HTML document -->
        <body>

      <header> 
          <h1> Hexamech Solutions </h1>
      </header>
      <nav>
        <ul>
          <li><a style="text-decoration: none; color: inherit;" href="./hexapodrobot.html">Hexapod Robot</a></li>
          <li><a style="text-decoration: none; color: inherit;" href="./LiveFeed.html">Livestream</a></li>
          <li><a style="text-decoration: none; color: inherit;" href="./index.html">Home</a></li>
          <li><a style="text-decoration: none; color: inherit;" href="./GetInTouch.html">Who We Are</a></li>
      </ul>
      </nav>    
         <div class="lidar-container">

          <div class="twitch-lidar"> 
            <!-- Livestream iframe with specified attributes -->
            <iframe src="https://player.twitch.tv/?channel=HipsterJester&parent=dailycodi.github.io" frameborder="0" allowfullscreen="true" scrolling="no" height="378" width="620"></iframe> 
            <h3 > LiDar Feed </h3>
            </div>
          
            <div class="embed-container">
              <h3 > LiDAR </h3>
              <p>When you visualize LiDAR data in RViz, a tool commonly used in the robotics community, particularly with ROS (Robot Operating System), you see a dynamic, real-time environment representation. RViz allows for the 3D visualization of sensor data and state information from ROS in an easy-to-understand and interpretable way. </p>
       
            </div>
          </div>
          
          <section class="feed-container">
            <h1 class="big-header">How it works</h1>
            <div class="box-container">
              <div class="left-box">
                <h3>What is LiDAR?</h3>
                <p> SLAM stands for Simultaneous Localization and Mapping. It's a technique used in robotics and autonomous systems to create maps of an unknown environment while simultaneously keeping track of the robot's location within that environment. Involves using LiDAR sensors to both perceive the surroundings and estimate the robot's position and orientation relative to those surroundings.</p>
                <img src="LearnPhotos/LiDARStock.jpg" alt="LiDAR" class="interactive-image">
           
              </div>
              <div class="right-boxes">
                <div class="boxlive">
                  <h3>Step 1</h3>
                  <p>SLAM stands for Simultaneous Localization and Mapping. It's a technique used in robotics and autonomous systems to create maps of an unknown environment while simultaneously keeping track of the robot's location within that environment. Involves using LiDAR sensors to both perceive the surroundings and estimate the robot's position and orientation relative to those surroundings.</p>
                  
                  <p> Our primary goal was to map the surrounding area for the user in 2D with accuracy and completeness. Employing LiDAR sensors, we aimed to create a detailed map depicting the layout of obstacles and features in the environment. Our focus was on providing the user with a clear visual representation of their surroundings to navigate effectively in two dimensions. </p>
                </div>
                <div class="boxlive">
                  <h3>Step 2</h3>
                  <p>The second step of SLAM involves extracting meaningful features from the sensor data to facilitate the mapping and localization processes, enabling the robot or user to navigate and interact effectively with the environment.</p>
                  <p>We opted for the Slamtec A1M8 LiDAR due to its affordability and widespread recommendation, making it an ideal choice for college students. Its competitive pricing and positive reviews made it stand out as the most suitable option for our budget-conscious project needs. The Slamtec A1M8's combination of affordability and performance ensured that we could effectively implement SLAM technology in our academic endeavors without exceeding our financial constraints.</p>
                </div>
                <div class="boxlive">
                  <h3>Step 3</h3>
                  <p>The last step of SLAM focuses on ensuring the reliability and consistency of the map and localization estimates, allowing the robot or user to navigate effectively and make informed decisions based on the environment's current state.</p>
                  <p>We seamlessly integrated all components to demonstrate live mapping, with the data being uploaded in real-time to our website. Users can now observe dynamic updates of the environment as it's mapped, providing an interactive and informative experience. This implementation enhances accessibility and enables users to remotely monitor and engage with the mapping process.</p>
                </div>
              </div>
            </div>
          </section>
          
        </body>
</html>
